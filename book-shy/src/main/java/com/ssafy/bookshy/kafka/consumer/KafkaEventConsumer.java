package com.ssafy.bookshy.kafka.consumer;

import com.ssafy.bookshy.domain.chat.dto.ChatMessageResponseDto;
import com.ssafy.bookshy.domain.chat.dto.ChatRoomDto;
import com.ssafy.bookshy.domain.chat.dto.ChatRoomUserIds;
import com.ssafy.bookshy.domain.chat.entity.ChatRoom;
import com.ssafy.bookshy.domain.chat.service.ChatMessageService;
import com.ssafy.bookshy.domain.chat.service.ChatRoomService;
import com.ssafy.bookshy.domain.notification.dto.ChatNotificationFcmDto;
import com.ssafy.bookshy.domain.notification.dto.MatchCompleteFcmDto;
import com.ssafy.bookshy.domain.notification.service.NotificationService;
import com.ssafy.bookshy.domain.users.entity.Users;
import com.ssafy.bookshy.domain.users.repository.UserRepository;
import com.ssafy.bookshy.kafka.dto.*;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.elasticsearch.action.index.IndexRequest;
import org.elasticsearch.action.index.IndexResponse;
import org.elasticsearch.client.RequestOptions;
import org.elasticsearch.client.RestHighLevelClient;
import org.elasticsearch.xcontent.XContentType;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.messaging.simp.SimpMessagingTemplate;
import org.springframework.stereotype.Service;

import java.io.IOException;
import java.util.HashMap;
import java.util.Map;
import java.util.Optional;

/**
 * ğŸ“¡ Kafka ì´ë²¤íŠ¸ë¥¼ ìˆ˜ì‹ í•˜ê³  í›„ì† ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” Consumer ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
 */
@Slf4j
@Service
@RequiredArgsConstructor
public class KafkaEventConsumer {

    private final ChatMessageService chatMessageService;
    private final ChatRoomService chatRoomService;
    private final SimpMessagingTemplate messagingTemplate;
    private final RestHighLevelClient elasticsearchClient;
    private final UserRepository userRepository;
    private final NotificationService notificationService;

    @Value("${app.developer.id}")
    private String developerId;

    @Value("${spring.profiles.active}")
    private String activeProfile;

    /**
     * ğŸ“˜ ì±… ë“±ë¡ ì´ë²¤íŠ¸ ìˆ˜ì‹  ì²˜ë¦¬
     * - í† í”½: {developerId}-book.created
     * - ë„ì„œ ë“±ë¡ ê´€ë ¨ ì´ë²¤íŠ¸ë¥¼ ìˆ˜ì‹ í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ìë¦¬ì…ë‹ˆë‹¤.
     */
    @KafkaListener(topics = "#{@kafkaTopicResolver.getBookCreatedTopic()}", containerFactory = "bookListenerFactory")
    public void listenBookCreated(ConsumerRecord<String, BookCreatedDto> record, Acknowledgment ack) {
        try {
            BookCreatedDto event = record.value();
            log.info("ğŸ“˜ Book Created Event received: {}", event);

            // TODO: ì±… ë“±ë¡ í›„ì²˜ë¦¬ ë¡œì§ ì‘ì„± í•„ìš”

            ack.acknowledge(); // âœ… ìˆ˜ë™ ì»¤ë°‹
        } catch (Exception e) {
            log.error("âŒ Error processing book.created event: {}", record.value(), e);
        }
    }

    /**
     * ğŸ¤ ë§¤ì¹­ ì„±ê³µ ì´ë²¤íŠ¸ ìˆ˜ì‹  ì²˜ë¦¬
     * - í† í”½: {developerId}-match.success
     * - ì±… êµí™˜ ë§¤ì¹­ì´ ì„±ì‚¬ë˜ì—ˆì„ ë•Œ í›„ì²˜ë¦¬ë¥¼ ìœ„í•œ Consumerì…ë‹ˆë‹¤.
     */
    @KafkaListener(topics = "#{@kafkaTopicResolver.getMatchSuccessTopic()}", containerFactory = "matchListenerFactory")
    public void listenMatchSuccess(ConsumerRecord<String, MatchSuccessDto> record, Acknowledgment ack) {
        try {
            MatchSuccessDto event = record.value();
            log.info("ğŸ¤ Match Success Event received: {}", event);

            // ğŸ”” ë§¤ì¹­ ì™„ë£Œ ì•Œë¦¼ ì „ì†¡
            String senderName = userRepository.findById(event.getUserAId())
                    .map(Users::getNickname)
                    .orElse("ìƒëŒ€ë°©");

            notificationService.sendMatchCompleteNotification(
                    MatchCompleteFcmDto.builder()
                            .receiverId(event.getUserBId())
                            .partnerName(senderName)
                            .chatRoomId(chatRoom.getId())
                            .build()
            );

            ack.acknowledge();
        } catch (Exception e) {
            log.error("âŒ Error processing match.success event: {}", record.value(), e);
        }
    }

    /**
     * ğŸ“¦ êµí™˜ ì™„ë£Œ ì´ë²¤íŠ¸ ìˆ˜ì‹  ì²˜ë¦¬
     * - í† í”½: {developerId}-trade.success
     * - ì‹¤ì œ ì±… êµí™˜ì´ ì™„ë£Œë˜ì—ˆì„ ë•Œ ë°œìƒí•˜ëŠ” ì´ë²¤íŠ¸ ì²˜ë¦¬
     */
    @KafkaListener(topics = "#{@kafkaTopicResolver.getTradeSuccessTopic()}", containerFactory = "recommendListenerFactory")
    public void listenTradeSuccess(ConsumerRecord<String, TradeSuccessDto> record, Acknowledgment ack) {
        try {
            TradeSuccessDto event = record.value();
            log.info("ğŸ“¦ Trade Success Event received: {}", event);

            // TODO: êµí™˜ ì™„ë£Œ í›„ì²˜ë¦¬ ë¡œì§ ì‘ì„± í•„ìš”

            ack.acknowledge();
        } catch (Exception e) {
            log.error("âŒ Error processing trade.success event: {}", record.value(), e);
        }
    }

    /**
     * ğŸ’¬ ì‹¤ì‹œê°„ ì±„íŒ… ë©”ì‹œì§€ ìˆ˜ì‹  ì²˜ë¦¬
     * - í† í”½: {developerId}-chat.message
     * - Kafkaë¥¼ í†µí•´ ì „ë‹¬ëœ ì±„íŒ… ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥í•˜ê³ ,
     * í•´ë‹¹ ì±„íŒ…ë°© êµ¬ë…ìë“¤ì—ê²Œ WebSocketìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
     */
    @KafkaListener(topics = "#{@kafkaTopicResolver.getChatMessageTopic()}", containerFactory = "chatListenerFactory")
    public void listenChatMessage(ConsumerRecord<String, ChatMessageKafkaDto> record, Acknowledgment ack) {
        try {
            ChatMessageKafkaDto dto = record.value();
            log.info("ğŸ“¥ [KafkaConsumer] Received ChatMessageKafkaDto from topic '{}': {}", record.topic(), dto);

            // ğŸ’¾ ë©”ì‹œì§€ë¥¼ DBì— ì €ì¥
            ChatMessageResponseDto saved = chatMessageService.saveMessageFromKafka(dto);
            log.info("ğŸ’¾ [KafkaConsumer] ChatMessage saved to DB: {}", saved);

            // ğŸ“¢ í•´ë‹¹ ì±„íŒ…ë°© êµ¬ë…ìì—ê²Œ ë©”ì‹œì§€ ì „ì†¡
            String destination = "/topic/chat/" + dto.getChatRoomId();
            messagingTemplate.convertAndSend(destination, saved);
            log.info("ğŸ“¢ [KafkaConsumer] ChatMessage sent to WebSocket destination '{}'", destination);

            // ğŸ”¥ ì±„íŒ… ëª©ë¡ ê°±ì‹ ìš© ë¸Œë¡œë“œìºìŠ¤íŠ¸
            ChatRoomUserIds userIds = chatRoomService.getUserIdsByChatRoomId(dto.getChatRoomId());
            Long senderId = dto.getSenderId();
            Long receiverId = userIds.getUserAId().equals(senderId)
                    ? userIds.getUserBId()
                    : userIds.getUserAId();

            // ğŸ‘¥ ê° ì‚¬ìš©ìì—ê²Œ ì±„íŒ… ëª©ë¡ ê°±ì‹  WebSocket ì „ì†¡
            ChatRoomDto chatRoomDto = chatRoomService.getChatRoomDtoByKafkaEvent(dto);

            messagingTemplate.convertAndSend("/topic/chat/user/" + senderId, chatRoomDto);
            messagingTemplate.convertAndSend("/topic/chat/user/" + receiverId, chatRoomDto);

            log.info("âœ… [KafkaConsumer] ì±„íŒ… ë³´ë‚¸ì´ Id: '{}', ë°›ëŠ”ì´ Id: '{}'", senderId, receiverId);

            // FCM ì•Œë¦¼ ì „ì†¡ (ë³¸ì¸ ì œì™¸ + ë¯¸ë¦¬ë³´ê¸° ê¸¸ì´ ì œí•œ)
            if (!senderId.equals(receiverId)) {
                String senderName = userRepository.findById(senderId)
                        .map(Users::getNickname)
                        .orElse("ì•Œ ìˆ˜ ì—†ìŒ");

                String preview = dto.getContent();
                if (preview.length() > 50) {
                    preview = preview.substring(0, 47) + "...";
                }

                notificationService.sendChatNotification(ChatNotificationFcmDto.builder()
                        .receiverId(receiverId)
                        .senderNickName(senderName)
                        .content(preview)
                        .chatRoomId(dto.getChatRoomId())
                        .build()
                );
            }

            ack.acknowledge(); // âœ… ì»¤ë°‹
            log.info("âœ… [KafkaConsumer] Offset committed for topic '{}'", record.topic());
        } catch (Exception e) {
            log.error("âŒ [KafkaConsumer] Error while processing chat.message", e);
        }
    }

    /**
     * ğŸ’¬ ì‹¤ì‹œê°„ ë¡œê¹… ë©”ì‹œì§€ ìˆ˜ì‹  ì²˜ë¦¬
     * - í”„ë¡œë•ì…˜ í™˜ê²½(prod)ì´ê±°ë‚˜ developerIdê°€ ë¹„ì–´ìˆìœ¼ë©´ "recommend.event" í† í”½ì„ ì‚¬ìš©
     * ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ "{developerId}-recommend.event" í˜•ì‹ìœ¼ë¡œ í† í”½ ì´ë¦„ ìƒì„±
     */
    @KafkaListener(topics = "#{@kafkaTopicResolver.getRecommendEventTopic()}", containerFactory = "recommendListenerFactory")
    public void listenRecommendEvent(ConsumerRecord<String, RecommendMessageKafkaDto> record, Acknowledgment ack) {
        try {
            String topic = record.topic();
            RecommendMessageKafkaDto logDto = record.value();

            log.info("ğŸš€ Kafka ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œì‘ - í† í”½: {}, ì´ë²¤íŠ¸íƒ€ì…: {}", topic, logDto.getEventType());

            // ë¡œê·¸ ë°ì´í„° ì¶”ì¶œ
            Map<String, Object> logData = new HashMap<>();
            logData.put("eventType", logDto.getEventType());
            logData.put("eventData", logDto.getEventData());
            logData.put("timestamp", logDto.getTimestamp());

            // ğŸ’¥ ì—¬ê¸°ì— ìƒì„¸ ë¡œê·¸ ì¶”ê°€!
            log.info("ğŸ” ë°›ì€ ë©”ì‹œì§€ ì •ë³´: í† í”½={}, íŒŒí‹°ì…˜={}, ì˜¤í”„ì…‹={}, ì´ë²¤íŠ¸íƒ€ì…={}, ì•„ì´í…œID={}, íƒ€ì„ìŠ¤íƒ¬í”„={}",
                    record.topic(),
                    record.partition(),
                    record.offset(),
                    logDto.getEventType(),
                    logDto.getEventData().get("itemId"),
                    logDto.getTimestamp());

            log.info("ğŸ”§ í˜„ì¬ ì„¤ì • - developerId: {}, activeProfile: {}", developerId, activeProfile);

            // ì¸ë±ìŠ¤ ì´ë¦„ - ê³µí†µ ì¸ë±ìŠ¤ ì‚¬ìš©
            String indexName = "recommend.event";

            // ë‹¨ìˆœí•œ ë¬¸ì„œ ID ìƒì„± - íƒ€ì„ìŠ¤íƒ¬í”„ë§Œ ì‚¬ìš© (í”„ë¡œë•ì…˜ì—ì„œëŠ” ì´ ì •ë„ë©´ ì¶©ë¶„)
            String docId = logDto.getEventType() + "-" + System.currentTimeMillis();

            log.info("ğŸ“ ES ì €ì¥ ì¤€ë¹„ - ì¸ë±ìŠ¤: {}, ë¬¸ì„œID: {}", indexName, docId);

            try {
                // ê°œë°œì IDê°€ 'subi'ì´ê±°ë‚˜ ì„œë²„ í™˜ê²½ì¼ ê²½ìš°ì—ëŠ”
                if ("subi".equals(developerId) || "prod".equals(activeProfile)) {
                    log.info("âœ… ES ì €ì¥ ì¡°ê±´ ì¶©ì¡±: developerId={}, activeProfile={}", developerId, activeProfile);

                    // Elasticsearchì— ì €ì¥
                    IndexRequest indexRequest = new IndexRequest(indexName)
                            .id(docId)
                            .source(logData, XContentType.JSON);

                    log.info("ğŸ“¤ ES ì¸ë±ì‹± ìš”ì²­ ì „ì†¡ ì¤‘...");
                    IndexResponse response = elasticsearchClient.index(indexRequest, RequestOptions.DEFAULT);

                    log.info("âœ¨ ESì— ë¡œê·¸ ì €ì¥ ì„±ê³µ: id={}, index={}, result={}",
                            response.getId(), indexName, response.getResult());
                } else {
                    // ë‹¤ë¥¸ ê°œë°œìì¸ ê²½ìš° ì €ì¥í•˜ì§€ ì•Šê³  ë¡œê·¸ë§Œ ë‚¨ê¹€
                    log.info("â­ï¸ ê°œë°œì ID '{}'ëŠ” 'subi'ê°€ ì•„ë‹ˆë¯€ë¡œ ES ì €ì¥ ìŠ¤í‚µ", developerId);
                }

                // ëª¨ë“  ê²½ìš°ì— ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œë¡œ í‘œì‹œ
                log.info("âœ… Kafka ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ - ACK ì „ì†¡");
                ack.acknowledge();

            } catch (IOException e) {
                log.error("âŒ ES ì €ì¥ ì¤‘ IOException ë°œìƒ: {}", e.getMessage());

                // ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ì¸ ê²½ìš° ì €ì¥ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                if (e.getMessage().contains("Unable to parse response body") &&
                        e.getMessage().contains("201 Created")) {
                    log.info("âš ï¸ ESì— ë¡œê·¸ ì €ì¥ ì¶”ì • ì„±ê³µ (ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ ë¬´ì‹œ): index={}", indexName);
                    ack.acknowledge();
                } else {
                    log.error("âŒ ESì— ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: index={}, error={}", indexName, e.getMessage());
                }
            }
        } catch (Exception e) {
            log.error("ğŸ’¥ ë¡œê·¸ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: ", e);
        }
    }
}
